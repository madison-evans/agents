# agents/graph_agent.py

from langchain_openai import ChatOpenAI
from agents.base_agent import Agent

from langchain.schema import HumanMessage, AIMessage, BaseMessage
from typing import List
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from typing_extensions import TypedDict, Annotated
from langgraph.checkpoint.memory import MemorySaver

class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

class GraphAgent(Agent):
    def __init__(self, OPENAI_API_KEY: str):
        self.OPENAI_API_KEY = OPENAI_API_KEY

        # Initialize the LLM
        self.llm = ChatOpenAI(
            openai_api_key=self.OPENAI_API_KEY,
            model="gpt-3.5-turbo"
        )

        # Initialize the StateGraph
        self.graph_builder = StateGraph(State)

        # Define the chatbot node
        def chatbot(state: State):
            messages = state["messages"]
            response = self.llm.invoke(messages)  # Use invoke method
            return {"messages": [response]}

        self.graph_builder.add_node("chatbot", chatbot)
        self.graph_builder.add_edge(START, "chatbot")
        self.graph_builder.add_edge("chatbot", END)

        # Initialize memory for session history
        self.memory = MemorySaver()

        # Compile the graph with checkpointing
        self.graph = self.graph_builder.compile(checkpointer=self.memory)

    def run(self, messages: List[HumanMessage], session_id: str = "default_session") -> AIMessage:
        # Prepare the state input
        state_input = {"messages": messages}
        config = {"configurable": {"thread_id": session_id}}

        # Run the graph
        events = self.graph.stream(state_input, config)

        # Collect the AI's response
        ai_response = None
        for event in events:
            # print("Event:", event)  # Debugging line
            for node_output in event.values():
                if "messages" in node_output and node_output["messages"]:
                    ai_response = node_output["messages"][-1]

        if ai_response is None:
            raise ValueError("No response generated by the agent.")

        return ai_response
